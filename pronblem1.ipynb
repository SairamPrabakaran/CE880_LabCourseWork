{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SairamPrabakaran/CE880_LabCourseWork/blob/main/pronblem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVDvR4xS98RT"
      },
      "source": [
        "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGCu7kuK98RW"
      },
      "outputs": [],
      "source": [
        "NAME = \"2315589\"\n",
        "COLLABORATORS = \"sagihaider\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ5Xzo9198RX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn56yWhW98RY"
      },
      "source": [
        "---\n",
        "# Welcome to CE880\n",
        "### This is your week-6 : Problem notebook\n",
        "\n",
        "For this problem set, we'll be using the Jupyter notebook and please upload this notebook to [Google Colab](https://colab.research.google.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhGF63In98RY"
      },
      "source": [
        "---\n",
        "## Question 1:\n",
        "\n",
        "Write a Python function to calculate the `false negative rate`, you need the `true labels` as well. The `false negative rate` is the proportion of `actual positive cases` that were incorrectly classified as `negative`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0303f241ebccf763a33d1398b2539117",
          "grade": false,
          "grade_id": "my_ttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "BoZ2j5Jl98RY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def calculate_false_negative_rate(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the false negative rate given the true labels and predicted labels.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (numpy.ndarray or list): True labels.\n",
        "    - y_pred (numpy.ndarray or list): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - false_negative_rate (float): False negative rate.\n",
        "    \"\"\"\n",
        "    # Convert predicted and true labels to NumPy arrays\n",
        "\n",
        "    predicition_labels = np.asarray(y_pred)\n",
        "    true_labels = np.asarray(y_true)\n",
        "\n",
        "    # Calculate True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN)\n",
        "\n",
        "    TP = np.sum(np.logical_and(predicition_labels==1,true_labels ==1))\n",
        "    TN = np.sum(np.logical_and(predicition_labels==0,true_labels ==0))\n",
        "    FP = np.sum(np.logical_and(predicition_labels==1,true_labels ==0))\n",
        "    FN = np.sum(np.logical_and(predicition_labels==0,true_labels ==1))\n",
        "    # Calculate False Negative Rate (FNR)\n",
        "\n",
        "    FNR = FN / (TP + FN)\n",
        "    # Print False Negative Rate and return it\n",
        "    print(FNR)\n",
        "    return FNR\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fc57c0e15c295507ebef212934e478f4",
          "grade": true,
          "grade_id": "my_ttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6IgvsRK98RZ",
        "outputId": "dfcd15a6-7f42-4a38-f417-006997378067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n",
            "0.4\n"
          ]
        }
      ],
      "source": [
        "# Check you solution by running this cell\n",
        "# Case 1\n",
        "y_true = [1, 0, 1, 1, 0, 0, 1, 0, 1]\n",
        "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1]\n",
        "assert calculate_false_negative_rate(y_true, y_pred) == 0.2\n",
        "\n",
        "# Case 2\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1]\n",
        "assert calculate_false_negative_rate(y_true, y_pred) == 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp2kbmXe98RZ"
      },
      "source": [
        "---\n",
        "## Question 2:\n",
        "\n",
        "Write Python code to calculate the `F1-score`, you need the `true labels` as well as the `predicted labels`. The `F1-score` is a measure of a model's accuracy that considers both the `precision` and `recall` of the model.\n",
        "\n",
        "<img src=\"https://lh6.googleusercontent.com/JJuhZfvr8tq3asFRvSJwb1CwqMLKCfZGpjy6Cng35RSvq-5eEa9I9TPUjs1M6jgTSP5H-EiXrr8URnoiRICHWPGDE-fwMKmZNwVDBARhO4LcUgpO4Nj_bfLLNCshBc3vrYgqUO2Nj-THYwkmbr1J9fE\" alt=\"drawing\" style=\"width:400px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "115516fdad289a9e6cdf3e2cb8c3980b",
          "grade": false,
          "grade_id": "my_pairedttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wlcYFeQe98Ra"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the F1-score given the true labels and predicted labels.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (numpy.ndarray or list): True labels.\n",
        "    - y_pred (numpy.ndarray or list): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - f1_score (float): F1-score.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    predicted_labels = np.asarray(y_pred)\n",
        "    true_labels = np.asarray(y_true)\n",
        "\n",
        "    # Calculate True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN)\n",
        "\n",
        "    TP = np.sum(np.logical_and(predicted_labels == 1, true_labels == 1))\n",
        "    TN = np.sum(np.logical_and(predicted_labels == 0, true_labels == 0))\n",
        "    FP = np.sum(np.logical_and(predicted_labels == 1, true_labels == 0))\n",
        "    FN = np.sum(np.logical_and(predicted_labels == 0, true_labels == 1))\n",
        "\n",
        "    # Calculate Precision and Recall\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    # Calculate F1-score\n",
        "    f1_score = round(2 * (precision * recall) / (precision + recall),2) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return f1_score\n",
        "\n",
        "\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "409382277e058dd310f9a7aa4542e79a",
          "grade": true,
          "grade_id": "my_pairedttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BRza0tZc98Ra"
      },
      "outputs": [],
      "source": [
        "# Check you solution by running this cell\n",
        "# Case 1 data\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1]\n",
        "assert calculate_f1_score(y_true, y_pred) == 0.6\n",
        "\n",
        "\n",
        "# # Case 2 data\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "assert calculate_f1_score(y_true, y_pred) == 0.62\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ONRsbKZ98Ra"
      },
      "source": [
        "---\n",
        "## Question 3:\n",
        "\n",
        "#### Shapiro-Wilk Test\n",
        "Tests whether a data sample has a Gaussian distribution.\n",
        "\n",
        "Assumptions\n",
        "\n",
        "* Observations in each sample are independent and identically distributed (iid).\n",
        "\n",
        "Interpretation\n",
        "\n",
        "* H0: the sample has a Gaussian distribution.\n",
        "* H1: the sample does not have a Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "46e413b53628a4d7763ce8b467327a5c",
          "grade": false,
          "grade_id": "my_normalityttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypxLqMUw98Rb",
        "outputId": "c2c7b3eb-da45-4452-8807-6c562c72cdbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1934097558259964"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
        "\n",
        "def my_normalityttest(data):\n",
        "    \"\"\"Write code to to check the normality of the data. In other words,\n",
        "    you are checking if the data is normally distributed and return p value.\n",
        "    Hint: Please see what is shapiro test and how you can use it\n",
        "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    statistic, p_value = shapiro(data)\n",
        "    return p_value\n",
        "    raise NotImplementedError()\n",
        "\n",
        "my_normalityttest(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ddf4ce4217df5678cc4c38ffb9623a47",
          "grade": true,
          "grade_id": "my_normalityttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gPgn-g3798Rb"
      },
      "outputs": [],
      "source": [
        "# Check you solution by running this cell\n",
        "import math\n",
        "assert math.isclose(my_normalityttest(data), 0.193, rel_tol = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgYSqMlV98Rc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}